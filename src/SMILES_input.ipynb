{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheminformatics Datasets \n",
    "https://github.com/GLambard/Molecules_Dataset_Collection/tree/master/latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dl_util import *\n",
    "from ml_util import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from eval_class_util import *\n",
    "from run_eval import split_fit_plot_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting SMILES and converting into sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>SMILE</th>\n",
       "      <th>Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.xyz</td>\n",
       "      <td>C[NH+]1CC1C(C)(C)O</td>\n",
       "      <td>-1879.273366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.xyz</td>\n",
       "      <td>COC1CNCC1=O</td>\n",
       "      <td>-1598.701542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.xyz</td>\n",
       "      <td>Nc1cccc(N)c1</td>\n",
       "      <td>-1633.722192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.xyz</td>\n",
       "      <td>O=CC1COCO1</td>\n",
       "      <td>-1256.754945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.xyz</td>\n",
       "      <td>N#CCOCCO</td>\n",
       "      <td>-1317.974723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File ID               SMILE       Energy\n",
       "0   0.xyz  C[NH+]1CC1C(C)(C)O -1879.273366\n",
       "1   1.xyz         COC1CNCC1=O -1598.701542\n",
       "2   2.xyz        Nc1cccc(N)c1 -1633.722192\n",
       "3   3.xyz          O=CC1COCO1 -1256.754945\n",
       "4   4.xyz            N#CCOCCO -1317.974723"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esol = pd.read_csv('eval_datasets/train.csv')\n",
    "esol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "esol_smiles = esol['SMILE'].tolist()\n",
    "esol_solubility = esol['Energy'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_esol_smiles = []\n",
    "for SMILE in esol_smiles:\n",
    "    len_esol_smiles += [len(SMILE)]\n",
    "    \n",
    "max_len_esol = max(len_esol_smiles)\n",
    "\n",
    "esol_vocab_size = generate_onehot_encoding(esol_smiles,'vocab_size')\n",
    "esol_vocab_size, max_len_esol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "esol_encodings = generate_onehot_encoding(esol_smiles)\n",
    "esol_sequences = sequence.pad_sequences(esol_encodings, maxlen=max_len_esol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dheerajreddy.p/miniconda3/envs/mlns/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /home/dheerajreddy.p/miniconda3/envs/mlns/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1062: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/dheerajreddy.p/miniconda3/envs/mlns/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1123: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 34, 32)            768       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 34, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 17, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 17, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 7,233.0\n",
      "Trainable params: 7,233.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers=2\n",
    "optimizer =\"adam\"\n",
    "model_type =\"regression\"\n",
    "model = Sequential()\n",
    "model.add(Embedding(esol_vocab_size,  32, input_length=max_len_esol))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "if layers==3:\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# if optimizer == \"adam\" and lr!= 0.001:\n",
    "#     print(\"Setting learning rate to\"+str(lr))\n",
    "#     optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "if model_type == \"classification\":\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['acc', precision,recall,auc])\n",
    "else:\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse',optimizer=optimizer, metrics=['mape'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y_train, y_test = train_test_split(esol_sequences, esol_solubility, test_size=0.2, random_state=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/5\n",
      "7200/7200 [==============================] - 2s - loss: 780.6718 - mean_absolute_percentage_error: 1.3819 - val_loss: 812.0225 - val_mean_absolute_percentage_error: 1.2716\n",
      "Epoch 2/5\n",
      "7200/7200 [==============================] - 2s - loss: 779.6038 - mean_absolute_percentage_error: 1.3763 - val_loss: 872.1462 - val_mean_absolute_percentage_error: 1.3106\n",
      "Epoch 3/5\n",
      "7200/7200 [==============================] - 2s - loss: 766.3839 - mean_absolute_percentage_error: 1.3692 - val_loss: 781.1762 - val_mean_absolute_percentage_error: 1.2508\n",
      "Epoch 4/5\n",
      "7200/7200 [==============================] - 2s - loss: 761.1423 - mean_absolute_percentage_error: 1.3728 - val_loss: 837.1888 - val_mean_absolute_percentage_error: 1.3321\n",
      "Epoch 5/5\n",
      "7200/7200 [==============================] - 2s - loss: 722.9485 - mean_absolute_percentage_error: 1.3441 - val_loss: 872.6360 - val_mean_absolute_percentage_error: 1.3614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14dcd5c3a710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X1_train, y_train, shuffle=True, validation_split=0.1,\\\n",
    "                        epochs=5, batch_size=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X1_test).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_predict), type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1684.03398063, -1649.43878195, -1474.12720006, -1126.64722885,\n",
       "       -1467.78308407])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.6750235199\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sklearn\n",
    "\n",
    "rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_test, y_predict))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.755345523899145"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test,y_predict = split_fit_plot_predict(cnn_model,  esol_sequences, esol_maccs, esol_solubility_standard, esol_vocab_size, max_len_esol, \"esol\",\\\n",
    "                      batch_size=4, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(y_test)):\n",
    "#     item = y_test[i]\n",
    "#     if item == 0:\n",
    "#         print(item,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(y_predict)):\n",
    "#     item = y_predict[i]\n",
    "#     if item == 0:\n",
    "#         print(item,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_fit_plot_predict(cnn_model,  esol_sequences, esol_maccs, esol_solubility, esol_vocab_size, max_len_esol, \"esol\",\\\n",
    "#                       batch_size=4, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlns_py27",
   "language": "python",
   "name": "mlns_py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
